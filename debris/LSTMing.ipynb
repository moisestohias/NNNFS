{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time # For timing\n",
    "import aux_fun as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return np.exp(x)/(1 + np.exp(x))\n",
    "\n",
    "def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b):\n",
    "    _, H = prev_h.shape\n",
    "    a = prev_h.dot(Wh) + x.dot(Wx) + b      # (1, 4*H)\n",
    "    i = sigmoid(a[:, 0:H])\n",
    "    f = sigmoid(a[:, H:2*H])\n",
    "    o = sigmoid(a[:, 2*H:3*H])\n",
    "    g = np.tanh(a[:, 3*H:4*H])              # (1, H)\n",
    "    next_c = f * prev_c + i * g             # (1, H)\n",
    "    next_h = o * (np.tanh(next_c))          # (1, H)\n",
    "    cache = x, prev_h, prev_c, Wx, Wh, b, a, i, f, o, g, next_c\n",
    "    return next_h, next_c, cache\n",
    "\n",
    "\n",
    "def lstm_forward(x, prev_h, Wx, Wh, b):\n",
    "    cache = []\n",
    "    prev_c = np.zeros_like(prev_h)\n",
    "    for i in range(x.shape[0]):     # 0 to seq_length-1\n",
    "        # (1, SeqLen) (1, H) (1, H) (SeqLen, 4*H) (H, 4*H) (4*H,)\n",
    "        # x[i][None], prev_h, prev_c, Wx,          Wh,     b\n",
    "        next_h, next_c, next_cache = lstm_step_forward(x[i][None], prev_h, prev_c, Wx, Wh, b)\n",
    "        prev_h = next_h\n",
    "        prev_c = next_c\n",
    "        cache.append(next_cache)\n",
    "        if i > 0:\n",
    "            h = np.append(h, next_h, axis=0)\n",
    "        else:\n",
    "            h = next_h\n",
    "    return h, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1050037 characters, 103 unique.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "seq_length = 100\n",
    "\n",
    "# load data\n",
    "input_file = 'quijote.txt'\n",
    "data, char_to_idx, idx_to_char, vocab_size = aux.load(input_file)\n",
    "print('data has %d characters, %d unique.' % (len(data), vocab_size))\n",
    "data_feed = aux.python_gen(data, seq_length, char_to_idx, vocab_size)\n",
    "\n",
    "# model dimensions (more hyperparameters)\n",
    "input_dim = vocab_size\n",
    "hidden_dim = 250\n",
    "\n",
    "# model parameters\n",
    "Wx = np.random.randn(input_dim, 4*hidden_dim) / np.sqrt(4*hidden_dim)   # input to hidden\n",
    "Wh = np.random.randn(hidden_dim, 4*hidden_dim) / np.sqrt(4*hidden_dim)  # hidden to hidden\n",
    "b = np.zeros(4*hidden_dim)                                              # hidden bias\n",
    "\n",
    "# history variables\n",
    "loss = [-np.log(1.0 / vocab_size)]      # loss at iteration 0\n",
    "smooth_loss = loss.copy()\n",
    "it = 0\n",
    "it_per_epoch = len(data) / seq_length\n",
    "prev_h = np.zeros((1, hidden_dim))      # reset LSTM memory\n",
    "prev_c = np.zeros_like(prev_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 103)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# char_to_idx: dict, idx_to_char: dict, vocab_size: int = 103\n",
    "# data :str,  len(data.split(\" \")) # 175920\n",
    "inputs, targets = next(data_feed) # tuple ((100, 103), (100, 103))\n",
    "# Wx.shape, Wh.shape # ((103, 1000), (250, 1000))\n",
    "\n",
    "# x[i][None], prev_h, prev_c, Wx, Wh, b \n",
    "# (1, 103) (1, 250) (1, 250) (103, 1000) (250, 1000) (1000,)\n",
    "\n",
    "# h_states, h_cache = lstm_forward(inputs, prev_h, Wx, Wh, b)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 250), (1, 250))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1, 103) (1, 250) (1, 250) (103, 1000) (250, 1000) (1000,)\n",
    "# x(1, SeqLen) \n",
    "# prev_h(1, H) \n",
    "# prev_c (1, H) \n",
    "# Wx (SeqLen, 4*H)\n",
    "# Wh (H, 4*H) \n",
    "# b (4*H)\n",
    "\n",
    "x =  inputs[0].reshape(1, -1) # (1, 103)\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b) # ((1, 250), (1, 250), ...)\n",
    "next_h.shape, next_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 250), (1, 250))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lstm_cell(Z, H, PrevCS, W_hh, W_ih, B):\n",
    "    a = Z@W_ih + H@W_hh + B\n",
    "    i,f,g,o = np.split(a, 4, axis=1) # Input, Forget,g (tanh-Activation) , Output\n",
    "    i,f,g,o = sigmoid(i), sigmoid(f), np.tanh(g), sigmoid(o)\n",
    "    c_out = f*PrevCS + i*g\n",
    "    h_out = o * np.tanh(c_out)\n",
    "    cache = i,f,o,g, c_out, PrevCS,x , h_out, Wx, Wh\n",
    "    cache = x, prev_h, prev_c, Wx, Wh, b, a, i, f, o, g, c_out\n",
    "    return h_out, c_out, cache\n",
    "\n",
    "h_out, c_out, cache = lstm_cell(x, prev_h, prev_c, Wh, Wx, b)\n",
    "# def lstm(X, h, c, W_hh, W_ih, b):\n",
    "#     H = np.zeros((X.shape[0], X.shape[1], h.shape[1]))\n",
    "#     for t in range(X.shape[0]):\n",
    "#         h, c = lstm_cell(X[t], h, c, W_hh, W_ih, b)\n",
    "#         H[t,:,:] = h # Batch Comes second for contiguous memory :,:\n",
    "#     return H, c\n",
    "h_out.shape, c_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 250), (1, 250))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b):\n",
    "    a = prev_h.dot(Wh) + x.dot(Wx) + b      # (1, 4*H)\n",
    "    i,f,g,o = np.split(a, 4, axis=1) # Input, Forget, g (tanh-Activation) , Output\n",
    "    i,f,g,o = sigmoid(i), sigmoid(f), np.tanh(g), sigmoid(o) # (1, H)\n",
    "    next_c = f * prev_c + i * g                              # (1, H)\n",
    "    next_h = o * (np.tanh(next_c))                           # (1, H)\n",
    "    cache = x, prev_h, prev_c, Wx, Wh, b, a, i, f, o, g, next_c\n",
    "    return next_h, next_c, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  inputs[0].reshape(1, -1) # (1, 103)\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b) # ((1, 250), (1, 250), ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 250), (1, 250))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_h.shape, next_c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
